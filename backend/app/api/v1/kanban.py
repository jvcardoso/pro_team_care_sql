"""
Endpoints FastAPI para o sistema Kanban Board.

Rotas:
- GET /kanban/board - Board completo
- GET /kanban/cards - Lista cards
- POST /kanban/cards - Cria card com IA
- GET /kanban/cards/{id} - Detalhes do card
- PUT /kanban/cards/{id} - Atualiza card
- DELETE /kanban/cards/{id} - Deleta card
- POST /kanban/cards/{id}/move - Move card (drag & drop)
- POST /kanban/cards/{id}/validate - Salva dados validados
- POST /kanban/cards/{id}/movements - Adiciona movimento
- GET /kanban/columns - Lista colunas
- POST /kanban/import-bm-xlsx - Importa cards do BusinessMap (XLSX)
- GET /kanban/analytics/itil-summary - Resumo ITIL por categoria
- GET /kanban/analytics/itil-cards - Lista cards com classifica√ß√£o ITIL
"""
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, status, Query, UploadFile, File
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
import csv
import io
import logging
import openpyxl
from io import BytesIO

from app.core.database import get_db
from app.core.dependencies import get_current_active_user
from app.services.kanban_service import KanbanService
from app.schemas.kanban import (
    CardCreate,
    CardCreateWithAI,
    CardResponse,
    CardWithDetails,
    CardWithAISuggestions,
    CardUpdate,
    CardMoveRequest,
    ValidatedCardData,
    CardMovementCreate,
    CardMovementUpdate,
    CardMovementResponse,
    CardColumnResponse,
    KanbanAnalyticsResponse,
    KanbanAnalyticsSummary
)
from app.models.user import User

router = APIRouter(prefix="/kanban", tags=["Kanban Board"])

logger = logging.getLogger(__name__)


# ============================================================================
# Board e Colunas
# ============================================================================

@router.get("/board")
async def get_board(
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Retorna board completo com todas as colunas e cards.
    """
    service = KanbanService(db)
    board = await service.get_board(current_user.company_id)  # type: ignore
    return board





@router.get("/columns", response_model=List[CardColumnResponse])
async def list_columns(
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Lista colunas do board.
    """
    service = KanbanService(db)
    columns = await service.column_repo.get_all(current_user.company_id)  # type: ignore
    return columns


# ============================================================================
# Cards - CRUD
# ============================================================================

@router.post("/cards", response_model=CardWithAISuggestions, status_code=status.HTTP_201_CREATED)
async def create_card(
    data: CardCreateWithAI,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Cria card e analisa com IA.
    
    Retorna card criado + sugest√µes da IA.
    """
    service = KanbanService(db)

    result = await service.create_card_with_ai(
        company_id=current_user.company_id,  # type: ignore
        user_id=current_user.id,  # type: ignore
        title=data.Title,
        original_text=data.OriginalText,
        column_id=data.ColumnID,
        priority=data.Priority,
        due_date=data.DueDate
    )

    return {
        **result["card"].__dict__,
        "ai_suggestions": result["ai_suggestions"]
    }


async def list_cards(
    column_id: Optional[int] = Query(None, description="Filtrar por coluna"),
    column_ids: Optional[str] = Query(None, description="Filtrar por m√∫ltiplas colunas (IDs separados por v√≠rgula)"),
    completed_from: Optional[str] = Query(None, description="Data inicial de conclus√£o (YYYY-MM-DD)"),
    completed_to: Optional[str] = Query(None, description="Data final de conclus√£o (YYYY-MM-DD)"),
    moved_from: Optional[str] = Query(None, description="Data inicial de movimenta√ß√£o (YYYY-MM-DD)"),
    moved_to: Optional[str] = Query(None, description="Data final de movimenta√ß√£o (YYYY-MM-DD)"),
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=500),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Lista cards da empresa.
    
    Filtros dispon√≠veis:
    - column_id: Filtrar por coluna espec√≠fica
    - column_ids: Filtrar por m√∫ltiplas colunas (ex: "1,3,5")
    - completed_from/completed_to: Filtrar cards conclu√≠dos no per√≠odo
    - moved_from/moved_to: Filtrar cards com movimenta√ß√£o no per√≠odo
    """
    from sqlalchemy import select, and_, or_
    from sqlalchemy.orm import selectinload
    from app.models.kanban import Card, CardColumn, CardMovement
    from datetime import datetime
    
    # Construir query base com JOIN para pegar ColumnName
    query = select(Card, CardColumn.ColumnName).join(
        CardColumn, Card.ColumnID == CardColumn.ColumnID
    ).where(
        and_(
            Card.CompanyID == current_user.company_id,
            Card.IsDeleted == False
        )
    )
    
    # Aplicar filtros de coluna
    if column_ids:
        # Filtro por m√∫ltiplas colunas
        try:
            col_ids = [int(cid.strip()) for cid in column_ids.split(',') if cid.strip()]
            if col_ids:
                query = query.where(Card.ColumnID.in_(col_ids))
        except ValueError:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="IDs de coluna inv√°lidos"
            )
    elif column_id:
        # Filtro por coluna √∫nica
        query = query.where(Card.ColumnID == column_id)

    # Priorizar filtro por movimenta√ß√£o se fornecido
    if moved_from and moved_to:
        try:
            date_from = datetime.strptime(moved_from, "%Y-%m-%d")
            date_to = datetime.strptime(moved_to, "%Y-%m-%d")
            from datetime import timedelta
            date_to = date_to + timedelta(days=1)

            # Juntar com movimentos e filtrar pela data do movimento
            query = query.join(CardMovement, Card.CardID == CardMovement.CardID).where(
                and_(
                    CardMovement.LogDate >= date_from,
                    CardMovement.LogDate < date_to
                )
            ).distinct()

        except ValueError:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Formato de data inv√°lido para filtro de movimenta√ß√£o. Use YYYY-MM-DD"
            )
    
    # Filtrar por per√≠odo de conclus√£o (se `moved` n√£o for usado)
    elif completed_from and completed_to:
        try:
            date_from = datetime.strptime(completed_from, "%Y-%m-%d")
            date_to = datetime.strptime(completed_to, "%Y-%m-%d")
            # Adicionar 1 dia √† data final para incluir todo o dia
            from datetime import timedelta
            date_to = date_to + timedelta(days=1)
            
            query = query.where(
                and_(
                    Card.CompletedDate.isnot(None),
                    Card.CompletedDate >= date_from,
                    Card.CompletedDate < date_to
                )
            )
        except ValueError:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Formato de data inv√°lido para filtro de conclus√£o. Use YYYY-MM-DD"
            )


@router.get("/cards/{card_id}", response_model=CardWithDetails)
async def get_card(
    card_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Busca card com todos os detalhes (assignees, tags, movements, etc.)
    """
    service = KanbanService(db)
    card_data = await service.get_card_with_details(
        card_id=card_id,
        company_id=current_user.company_id  # type: ignore
    )

    if not card_data:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Card n√£o encontrado"
        )

    return {
        **card_data["card"].__dict__,
        "assignees": card_data["assignees"],
        "tags": card_data["tags"],
        "movements": card_data["movements"],
        "total_time_spent": card_data["total_time_spent"]
    }


@router.put("/cards/{card_id}", response_model=CardResponse)
async def update_card(
    card_id: int,
    data: CardUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Atualiza card.
    """
    service = KanbanService(db)

    # Converter para dict removendo None
    update_data = data.model_dump(exclude_unset=True)

    card = await service.card_repo.update(
        card_id=card_id,
        company_id=current_user.company_id,  # type: ignore
        **update_data
    )

    if not card:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Card n√£o encontrado"
        )

    return card


@router.delete("/cards/{card_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_card(
    card_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Deleta card (soft delete).
    """
    service = KanbanService(db)

    success = await service.card_repo.delete(
        card_id=card_id,
        company_id=current_user.company_id  # type: ignore
    )

    if not success:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Card n√£o encontrado"
        )

    return None


# ============================================================================
# Analytics / BI
# ============================================================================

@router.get("/analytics", response_model=KanbanAnalyticsResponse)
async def get_kanban_analytics(
    start_date: str = Query(..., description="Data inicial (YYYY-MM-DD)"),
    end_date: str = Query(..., description="Data final (YYYY-MM-DD)"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Retorna analytics do Kanban Board.

    **M√©tricas inclu√≠das:**
    - Throughput: Cards conclu√≠dos no per√≠odo
    - WIP: Cards em andamento
    - Lead Time: Tempo m√©dio cria√ß√£o ‚Üí conclus√£o
    - Cycle Time: Tempo m√©dio trabalho ‚Üí conclus√£o
    - SLA Compliance: % de cards no prazo
    - Time per Stage: Tempo m√©dio por coluna
    - Throughput History: Evolu√ß√£o di√°ria
    """
    import json
    from datetime import datetime

    # Validar datas
    try:
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    except ValueError:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Formato de data inv√°lido. Use YYYY-MM-DD"
        )

    if start_dt > end_dt:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Data inicial deve ser anterior √† data final"
        )

    # Obter company_id do usu√°rio
    company_id = current_user.company_id
    if not company_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Usu√°rio deve pertencer a uma empresa"
        )

    # Calcular m√©tricas diretamente no Python (mais confi√°vel que SP)
    try:
        from sqlalchemy import text
        from app.schemas.kanban import KanbanAnalyticsSummary

        # Query para obter dados da view
        movements_query = text("""
        SELECT
            CardID,
            CardCreatedAt,
            OldColumnName,
            NewColumnName,
            MovementDate,
            TimeInStageSeconds,
            DueDate
        FROM [analytics].[vw_CardFullHistory]
        WHERE CompanyID = :company_id
          AND MovementDate BETWEEN :start_date AND :end_date
        """)

        movements_result = await db.execute(movements_query, {
            "company_id": company_id,
            "start_date": start_date,
            "end_date": end_date
        })

        movements = movements_result.fetchall()

        # Query para WIP (cards em andamento)
        wip_query = text("""
        SELECT COUNT(DISTINCT c.CardID) AS WIPCount
        FROM [core].[Cards] c
        WHERE c.CompanyID = :company_id
          AND c.IsDeleted = 0
          AND c.CompletedDate IS NULL
          AND c.ColumnID IN (
              SELECT cc.ColumnID
              FROM core.CardColumns cc
              WHERE cc.CompanyID = :company_id
                AND cc.ColumnName NOT IN ('Backlog', 'Conclu√≠do')
          )
        """)

        wip_result = await db.execute(wip_query, {"company_id": company_id})
        wip_count = wip_result.scalar() or 0

        if not movements:
            logger.warning(f"No movement data found for CompanyID: {company_id}, StartDate: {start_date}, EndDate: {end_date}")
            # Retornar dados vazios
            return KanbanAnalyticsResponse(
                summary=KanbanAnalyticsSummary(
                    leadTimeAvgSeconds=None,
                    cycleTimeAvgSeconds=None,
                    throughput=0,
                    wip=0,
                    slaCompliance=0.0
                ),
                timePerStage=[],
                throughputHistory=[]
            )

        # Calcular m√©tricas do summary
        card_timings = {}
        throughput_history = {}
        time_per_stage = {}

        for row in movements:
            card_id = row[0]
            created_at = row[1]
            old_column = row[2]
            new_column = row[3]
            movement_date = row[4]
            time_in_stage = row[5] or 0
            due_date = row[6]

            # Coletar dados por card
            if card_id not in card_timings:
                card_timings[card_id] = {
                    'created_at': created_at,
                    'start_date': None,
                    'completed_date': None,
                    'due_date': due_date
                }

            # Data que saiu do backlog (in√≠cio do trabalho)
            if old_column == 'Backlog' and not card_timings[card_id]['start_date']:
                card_timings[card_id]['start_date'] = movement_date

            # Data de conclus√£o
            if new_column == 'Conclu√≠do':
                card_timings[card_id]['completed_date'] = movement_date
                # Adicionar ao throughput history
                date_key = movement_date.date().isoformat()
                throughput_history[date_key] = throughput_history.get(date_key, 0) + 1

            # Tempo por stage
            if old_column:
                if old_column not in time_per_stage:
                    time_per_stage[old_column] = []
                time_per_stage[old_column].append(time_in_stage)

            # WIP ser√° calculado separadamente com query direta na tabela Cards

        # Calcular m√©dias
        lead_times = []
        cycle_times = []
        sla_compliant = 0
        total_completed = 0

        for card_data in card_timings.values():
            if card_data['completed_date']:
                total_completed += 1
                # Lead time: cria√ß√£o at√© conclus√£o
                lead_time = (card_data['completed_date'] - card_data['created_at']).total_seconds()
                lead_times.append(lead_time)

                # Cycle time: in√≠cio trabalho at√© conclus√£o
                if card_data['start_date']:
                    cycle_time = (card_data['completed_date'] - card_data['start_date']).total_seconds()
                    cycle_times.append(cycle_time)

                # SLA compliance
                if card_data['due_date'] and card_data['completed_date'] <= card_data['due_date']:
                    sla_compliant += 1

        # Calcular m√©tricas finais
        lead_time_avg = sum(lead_times) / len(lead_times) if lead_times else None
        cycle_time_avg = sum(cycle_times) / len(cycle_times) if cycle_times else None
        throughput = total_completed
        wip = wip_count
        sla_compliance = sla_compliant / total_completed if total_completed > 0 else 0.0

        # Preparar time per stage
        time_per_stage_list = []
        for stage, times in time_per_stage.items():
            if times:
                avg_time = sum(times) / len(times)
                time_per_stage_list.append({
                    'columnName': stage,
                    'avgSeconds': int(avg_time)
                })

        # Preparar throughput history
        throughput_history_list = []
        for date_str, count in sorted(throughput_history.items()):
            throughput_history_list.append({
                'date': date_str,
                'count': count
            })

        # Preparar resposta final
        analytics_response = KanbanAnalyticsResponse(
            summary=KanbanAnalyticsSummary(
                leadTimeAvgSeconds=lead_time_avg,
                cycleTimeAvgSeconds=cycle_time_avg,
                throughput=throughput,
                wip=wip,
                slaCompliance=sla_compliance
            ),
            timePerStage=time_per_stage_list,
            throughputHistory=throughput_history_list
        )

        return analytics_response

    except Exception as e:
        logger.error(f"Error calculating analytics: {e}")
        # Retornar dados mockados para evitar erro 500 na interface
        return KanbanAnalyticsResponse(
            summary=KanbanAnalyticsSummary(
                leadTimeAvgSeconds=None,
                cycleTimeAvgSeconds=None,
                throughput=0,
                wip=0,
                slaCompliance=0.0
            ),
            timePerStage=[],
            throughputHistory=[]
        )

        # Preparar resposta final
        analytics_response = KanbanAnalyticsResponse(
            summary=KanbanAnalyticsSummary(
                leadTimeAvgSeconds=lead_time_avg,
                cycleTimeAvgSeconds=cycle_time_avg,
                throughput=throughput,
                wip=wip,
                slaCompliance=sla_compliance
            ),
            timePerStage=time_per_stage_list,
            throughputHistory=throughput_history_list
        )

        return analytics_response

    except Exception as e:
        logger.error(f"Error calculating analytics: {e}")
        # Retornar dados mockados para evitar erro 500 na interface
        return KanbanAnalyticsResponse(
            summary=KanbanAnalyticsSummary(
                leadTimeAvgSeconds=None,
                cycleTimeAvgSeconds=None,
                throughput=0,
                wip=0,
                slaCompliance=0.0
            ),
            timePerStage=[],
            throughputHistory=[]
        )


@router.get("/analytics/cards-in-period", response_model=List[CardResponse])
async def get_cards_in_period(
    start_date: str = Query(..., description="Data inicial (YYYY-MM-DD)"),
    end_date: str = Query(..., description="Data final (YYYY-MM-DD)"),
    column_ids: str = Query(None, description="IDs das colunas separados por v√≠rgula (deprecated - mantido para compatibilidade)"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Busca todos os cards relevantes para analytics no per√≠odo especificado.
    Usa Stored Procedure [core].[sp_GetAnalyticsCardsDetails] para consist√™ncia com m√©tricas.

    Usado pela tabela na p√°gina de analytics.
    """
    from app.repositories.base import BaseRepository

    company_id = current_user.company_id
    if not company_id:
        raise HTTPException(status_code=400, detail="Usu√°rio n√£o pertence a uma empresa.")

    try:
        # Validar datas
        from datetime import datetime
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")

        if start_dt > end_dt:
            raise HTTPException(
                status_code=400,
                detail="Data inicial deve ser anterior √† data final"
            )

        # Usar BaseRepository para executar a Stored Procedure
        repo = BaseRepository(None, db)  # Model n√£o necess√°rio para SP

        sp_name = "[core].[sp_GetAnalyticsCardsDetails]"
        sp_params = {
            "StartDate": start_date,
            "EndDate": end_date,
            "CompanyID": company_id,
            "UserID": current_user.id  # Opcional, pode ser None
        }

        # Executar Stored Procedure
        cards_data = await repo.execute_stored_procedure(sp_name, sp_params)

        # Mapear resultado para o schema de resposta
        return [
            {
                "CardID": card["CardID"],
                "Title": card["Title"],
                "Description": card["Description"],
                "Priority": card["Priority"],
                "CompanyID": card["CompanyID"],
                "UserID": card["UserID"],
                "ColumnID": card["ColumnID"],
                "ColumnName": card["ColumnName"],
                "CreatedAt": card["CreatedAt"],
                "CompletedDate": card["CompletedDate"],
                "DueDate": card["DueDate"],
                "IsDeleted": card["IsDeleted"]
            } for card in cards_data
        ]

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Formato de data inv√°lido: {str(e)}"
        )
    except Exception as e:
        logger.error(f"Error fetching cards in period via SP: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno ao buscar cards no per√≠odo: {str(e)}"
        )


# ============================================================================
# Opera√ß√µes Especiais

@router.post("/cards/{card_id}/move", response_model=CardResponse)
async def move_card(
    card_id: int,
    data: CardMoveRequest,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Move card para outra coluna (drag & drop).
    Cria movimento de auditoria automaticamente.
    """
    service = KanbanService(db)

    try:
        card = await service.move_card(
            card_id=card_id,
            company_id=current_user.company_id,  # type: ignore
            user_id=current_user.id,  # type: ignore
            new_column_id=data.NewColumnID,
            new_position=data.NewDisplayOrder
        )
        return card

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=str(e)
        )


@router.post("/cards/{card_id}/validate")
async def save_validated_data(
    card_id: int,
    validated_data: ValidatedCardData,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Salva dados validados pelo usu√°rio ap√≥s an√°lise da IA.
    
    Cria assignees, tags e movements.
    """
    service = KanbanService(db)

    success = await service.save_validated_data(
        card_id=card_id,
        company_id=current_user.company_id,  # type: ignore
        user_id=current_user.id,  # type: ignore
        validated_data=validated_data.model_dump()
    )

    if not success:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Erro ao salvar dados validados"
        )

    return {"message": "Dados validados salvos com sucesso"}


@router.post("/cards/{card_id}/movements", response_model=CardMovementResponse, status_code=status.HTTP_201_CREATED)
async def add_movement(
    card_id: int,
    data: CardMovementCreate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Adiciona movimento/lan√ßamento ao card.
    """
    service = KanbanService(db)

    try:
        movement = await service.add_movement(
            card_id=card_id,
            company_id=current_user.company_id,  # type: ignore
            user_id=current_user.id,  # type: ignore
            subject=data.Subject,
            description=data.Description,
            time_spent=data.TimeSpent
        )
        return movement

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=str(e)
        )


@router.put("/movements/{movement_id}", response_model=CardMovementResponse)
async def update_movement(
    movement_id: int,
    data: CardMovementUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Atualiza movimento/lan√ßamento existente.
    """
    logger.info(f"Atualizando movimento {movement_id} com dados: {data}")
    service = KanbanService(db)

    try:
        movement = await service.movement_repo.update(
            movement_id=movement_id,
            subject=data.Subject,
            description=data.Description,
            time_spent=data.TimeSpent
        )
        
        if not movement:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Movimento n√£o encontrado"
            )
        
        return movement
    
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao atualizar movimento: {str(e)}"
        )


@router.delete("/movements/{movement_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_movement(
    movement_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Deleta movimento/lan√ßamento.
    """
    service = KanbanService(db)
    
    success = await service.movement_repo.delete(movement_id)
    
    if not success:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Movimento n√£o encontrado"
        )
    
    return None


@router.post("/cards/{card_id}/complete", response_model=CardResponse)
async def complete_card(
    card_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Marca card como conclu√≠do.
    Move para coluna "Conclu√≠do" e registra data de conclus√£o.
    """
    service = KanbanService(db)

    try:
        card = await service.complete_card(
            card_id=card_id,
            company_id=current_user.company_id,  # type: ignore
            user_id=current_user.id  # type: ignore
        )
        return card

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=str(e)
        )


# ============================================================================
# Tags
# ============================================================================

@router.post("/cards/{card_id}/tags", status_code=status.HTTP_201_CREATED)
async def add_tag_to_card(
    card_id: int,
    tag_data: dict,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Adiciona tag ao card.
    """
    from app.repositories.kanban_repository import CardTagRepository
    from datetime import datetime
    
    tag_name = tag_data.get("TagName")
    if not tag_name:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="TagName √© obrigat√≥rio"
        )
    
    tag_repo = CardTagRepository(db)
    tag = await tag_repo.create(
        card_id=card_id,
        tag_name=tag_name
    )
    
    return {"message": "Tag adicionada com sucesso", "tag_id": tag.CardTagID}


@router.delete("/tags/{tag_id}", status_code=status.HTTP_204_NO_CONTENT)
async def remove_tag(
    tag_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Remove tag.
    """
    from app.repositories.kanban_repository import CardTagRepository
    
    tag_repo = CardTagRepository(db)
    success = await tag_repo.delete(tag_id)
    
    if not success:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Tag n√£o encontrada"
        )


# ============================================================================
# Importa√ß√£o de Cards do BusinessMap
# ============================================================================

@router.post("/import-bm-xlsx")
async def import_businessmap_xlsx(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Importa cards do BusinessMap via arquivo XLSX.
    
    Formato esperado:
    - Coluna A (0): Card ID
    - Coluna B (1): Custom ID
    - Coluna C (2): Color
    - Coluna D (3): Title
    - Coluna E (4): Owner
    - Coluna F (5): Deadline
    - Coluna G (6): Priority
    - Coluna H (7): Column Name
    - Coluna I (8): Board Name
    - Coluna J (9): Owners
    - Coluna K (10): Description
    - Coluna L (11): Lane Name
    - Coluna M (12): Actual End Date (IGNORADA - geralmente vazia)
    - Coluna N (13): Last End Date (USAR PARA CompletedDate)
    - Coluna O (14): Last Start Date (USAR PARA StartDate)
    - Coluna P (15): Planned Start
    - Coluna Q (16): Last Comment
    - Coluna R (17): Card URL
    """
    
    print("=" * 80)
    print("üéØ IMPORTA√á√ÉO BUSINESSMAP XLSX INICIADA!")
    print("=" * 80)
    
    try:
        # Ler arquivo
        print("üìñ Lendo arquivo XLSX...")
        contents = await file.read()
        print(f"üìÑ Tamanho: {len(contents)} bytes")
        
        if len(contents) == 0:
            raise HTTPException(status_code=400, detail="Arquivo vazio")
        
        # Carregar workbook
        print("üìä Carregando workbook...")
        wb = openpyxl.load_workbook(BytesIO(contents), data_only=True)
        ws = wb.active

        if ws is None:
            raise HTTPException(status_code=400, detail="N√£o foi poss√≠vel carregar a planilha ativa do arquivo XLSX")

        print(f"üìã Planilha ativa: {ws.title}")
        print(f"üìä Dimens√µes: {ws.max_row} linhas x {ws.max_column} colunas")

        # Verificar se h√° dados suficientes
        if ws.max_row < 2:
            raise HTTPException(status_code=400, detail="Arquivo deve ter pelo menos cabe√ßalho e uma linha de dados")

        # Ler cabe√ßalho (linha 1)
        header = [cell.value for cell in ws[1]]
        print(f"üìã Cabe√ßalho: {header[:5]}...")

        # Estat√≠sticas
        total = 0
        processed = 0
        created = 0
        updated = 0
        errors = 0

        # Processar linhas (come√ßando da linha 2)
        print(f"üîÑ Processando {ws.max_row - 1} linhas...")

        for row_num in range(2, ws.max_row + 1):
            row = ws[row_num]
            
            # Extrair valores das c√©lulas
            values = [cell.value for cell in row]
            
            # Validar linha (pelo menos ID e t√≠tulo)
            if not values[0] or not values[3]:
                print(f"‚ö†Ô∏è Linha {row_num} ignorada - sem ID ou t√≠tulo")
                errors += 1
                continue
            
            total += 1
            
            try:
                # Mapear dados
                card_data = {
                    "external_card_id": str(values[0]).strip() if values[0] else f"IMPORT-{total}",
                    "title": str(values[3]).strip() if values[3] else f"Card Importado #{total}",
                    "description": str(values[10]).strip() if values[10] else None,
                    "owner_name": str(values[4]).strip() if values[4] else None,
                    "deadline_str": str(values[5]) if values[5] else None,
                    "priority": str(values[6]).strip() if values[6] else "Average",
                    "column_name": str(values[7]).strip() if values[7] else None,
                    "actual_end_date_str": str(values[13]) if values[13] else None,  # Coluna N: Last End Date
                    "last_start_date_str": str(values[14]) if values[14] else None,  # Coluna O: Last Start Date
                    "last_comment": str(values[16]).strip() if len(values) > 16 and values[16] else None,  # Coluna Q
                    "card_url": str(values[17]).strip() if len(values) > 17 and values[17] else None,  # Coluna R
                }
                
                print(f"üìù [{total}] {card_data['external_card_id']} - {card_data['title'][:40]}...")
                
                # Executar SP
                sp_query = text("""
                    DECLARE @NewCardIDOut INT;
                    DECLARE @ActionTakenOut NVARCHAR(10);
                    
                    EXEC [core].[sp_UpsertCardFromImport]
                        @ExternalCardID = :external_card_id,
                        @Title = :title,
                        @Description = :description,
                        @OwnerName = :owner_name,
                        @DeadlineStr = :deadline_str,
                        @Priority = :priority,
                        @ColumnName = :column_name,
                        @ActualEndDateStr = :actual_end_date_str,
                        @LastStartDateStr = :last_start_date_str,
                        @LastComment = :last_comment,
                        @CardURL = :card_url,
                        @CompanyID = :company_id,
                        @DefaultUserID = :user_id,
                        @NewCardID = @NewCardIDOut OUTPUT,
                        @ActionTaken = @ActionTakenOut OUTPUT;
                    
                    SELECT @NewCardIDOut AS NewCardID, @ActionTakenOut AS ActionTaken;
                """)
                
                result = await db.execute(sp_query, {
                    **card_data,
                    "company_id": current_user.company_id,
                    "user_id": current_user.id
                })
                
                sp_result = result.fetchone()
                result.close()
                
                if sp_result and sp_result.ActionTaken:
                    action = sp_result.ActionTaken
                    if action == 'CREATED':
                        created += 1
                    elif action == 'UPDATED':
                        updated += 1
                    processed += 1
                    print(f"‚úÖ {action}: {card_data['external_card_id']}")
                else:
                    print("‚ö†Ô∏è SP n√£o retornou resultado")
                    errors += 1
                    
            except Exception as e:
                print(f"‚ùå Erro linha {row_num}: {str(e)}")
                errors += 1
        
        # Commit ou rollback
        if errors == 0:
            await db.commit()
            print("‚úÖ Transa√ß√£o comitada")
        else:
            await db.rollback()
            print(f"‚ö†Ô∏è {errors} erros - transa√ß√£o revertida")
        
        result = {
            "total": total,
            "processed": processed,
            "created": created,
            "updated": updated,
            "errors": errors
        }
        
        print(f"‚úÖ FINAL: {result}")
        return result
        
    except Exception as e:
        print(f"üí• ERRO: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao processar XLSX: {str(e)}"
        )


@router.get("/test-import")
async def test_import_endpoint():
    """Endpoint de teste para verificar se o backend est√° funcionando"""
    print("üß™ Endpoint de teste chamado!")
    return {"status": "ok", "message": "Backend funcionando"}

@router.post("/simple-test")
async def simple_test():
    """Teste muito simples"""
    return {"ok": True}

@router.post("/debug-import")
async def debug_import(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_active_user)
):
    """Endpoint de debug para verificar se arquivo chega"""
    print("=" * 50)
    print("üêõ DEBUG IMPORT CHAMADO!")
    print(f"üë§ User: {current_user.email_address}")
    print(f"üìÅ File: {file.filename}")
    print(f"üìÑ Type: {file.content_type}")
    print(f"üìè Size: {file.size}")

    try:
        contents = await file.read()
        print(f"üìñ Read: {len(contents)} bytes")
        decoded = contents.decode('utf-8')
        print(f"üî§ Decoded: {len(decoded)} chars")
        print(f"üìÑ Preview: {decoded[:200]}...")

        return {
            "received": True,
            "filename": file.filename,
            "size": len(contents),
            "content_length": len(decoded),
            "user": current_user.email_address
        }
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return {"error": str(e)}

@router.post("/debug-import-no-auth")
async def debug_import_no_auth(file: UploadFile = File(...)):
    """Endpoint de debug sem autentica√ß√£o"""
    print("=" * 50)
    print("üêõ DEBUG IMPORT SEM AUTH CHAMADO!")
    print(f"üìÅ File: {file.filename}")

    try:
        contents = await file.read()
        print(f"üìñ Read: {len(contents)} bytes")

        return {
            "received": True,
            "filename": file.filename,
            "size": len(contents)
        }
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return {"error": str(e)}

@router.post("/import-bm-test")
async def import_businessmap_csv_test(
    file: UploadFile = File(...)
):
    """Endpoint de teste SEM autentica√ß√£o para debug"""
    print("üß™ Endpoint de teste chamado!")

    try:
        contents = await file.read()
        print(f"üìÑ Arquivo lido: {len(contents)} bytes")

        if len(contents) == 0:
            return {"error": "Arquivo vazio"}

        decoded = contents.decode('utf-8')
        print(f"üìÑ Decodificado: {len(decoded)} chars")
        print(f"üìÑ Conte√∫do: {decoded[:100]}...")

        return {"status": "ok", "size": len(contents)}

    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return {"error": str(e)}

@router.post("/test-sp-import")
async def test_sp_import(
    db: AsyncSession = Depends(get_db)
):
    """Teste direto da Stored Procedure"""
    try:
        # Usar dados de teste
        test_data = {
            "external_card_id": "TEST-SP-001",
            "title": "Teste SP Database-First",
            "description": "Teste da Stored Procedure corrigida",
            "owner_name": "admin@proteamcare.com.br",
            "deadline_str": "2025-12-01",
            "priority": "High",
            "column_name": "Backlog",
            "actual_end_date_str": None,
            "last_start_date_str": None,
            "last_comment": "Teste de importa√ß√£o via SP",
            "card_url": "https://businessmap.com/test",
            "company_id": 1,
            "user_id": 1
        }

        sp_query = text("""
            EXEC [core].[sp_UpsertCardFromImport]
                @ExternalCardID = :external_card_id,
                @Title = :title,
                @Description = :description,
                @OwnerName = :owner_name,
                @DeadlineStr = :deadline_str,
                @Priority = :priority,
                @ColumnName = :column_name,
                @ActualEndDateStr = :actual_end_date_str,
                @LastStartDateStr = :last_start_date_str,
                @LastComment = :last_comment,
                @CardURL = :card_url,
                @CompanyID = :company_id,
                @DefaultUserID = :user_id
        """)

        result = await db.execute(sp_query, test_data)
        sp_result = result.fetchone()

        if sp_result:
            return {
                "success": True,
                "sp_result": {
                    "NewCardID": sp_result[0],
                    "ActionTaken": sp_result[1]
                },
                "message": "SP executada com sucesso"
            }
        else:
            return {
                "success": False,
                "message": "SP n√£o retornou resultado"
            }

        result = await db.execute(sp_query, test_data)
        sp_result = result.fetchone()

        await db.commit()

        # Convert result to dict for JSON serialization
        result_dict = None
        if sp_result:
            result_dict = {
                "CardID": sp_result[0],
                "Action": sp_result[1],
                "ExternalCardID": sp_result[2]
            }

        return {
            "success": True,
            "sp_result": result_dict,
            "message": "SP executada com sucesso"
        }

    except Exception as e:
        await db.rollback()
        return {
            "success": False,
            "error": str(e),
            "message": "Erro na execu√ß√£o da SP"
        }

@router.post("/import-bm-no-auth")
async def import_businessmap_csv_no_auth(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db)
):
    """Endpoint de importa√ß√£o SEM autentica√ß√£o para debug"""
    print("=" * 80)
    print("üéØ IMPORTA√á√ÉO BUSINESSMAP SEM AUTH - DEBUG!")
    print("=" * 80)

    # Usar usu√°rio admin hardcoded para teste
    query = text("""
        EXEC [core].[sp_get_user_for_auth]
            @email_attempted = :email
    """)

    result = await db.execute(query, {"email": "admin@proteamcare.com.br"})
    row = result.fetchone()

    if not row:
        return {"error": "Usu√°rio admin n√£o encontrado"}

    # Criar objeto user-like
    class MockUser:
        def __init__(self, row):
            self.id = row.id
            self.company_id = row.company_id
            self.email_address = "admin@proteamcare.com.br"

    current_user = MockUser(row)

    print(f"üë§ Usu√°rio de teste: {current_user.email_address} (ID: {current_user.id})")
    print(f"üè¢ Empresa: {current_user.company_id}")

    # Inicializar service
    service = KanbanService(db)

    # Verificar se arquivo foi enviado
    if not file:
        return {"error": "Arquivo n√£o enviado"}

    print(f"üìÅ Arquivo: {file.filename}")
    print(f"üìÑ Tipo: {file.content_type}")
    print(f"üìè Tamanho: {file.size}")

    # Validar arquivo
    if not file.filename or not file.filename.lower().endswith('.csv'):
        print("‚ùå Arquivo inv√°lido")
        return {"error": "Arquivo deve ser CSV"}

    try:
        print("üìñ Lendo arquivo...")
        contents = await file.read()
        print(f"üìÑ Tamanho: {len(contents)} bytes")

        if len(contents) == 0:
            print("‚ùå Arquivo vazio")
            return {"error": "Arquivo vazio"}

        print("üîÑ Decodificando...")
        decoded = contents.decode('utf-8')
        print(f"üìÑ Texto: {len(decoded)} caracteres")
        print(f"üìÑ Preview: {decoded[:100]}...")

        print("üìä Processando CSV com suporte a multilinha...")
        csv_reader = csv.reader(io.StringIO(decoded), delimiter=';', quoting=csv.QUOTE_ALL, doublequote=True)

        # Pular cabe√ßalho
        try:
            header = next(csv_reader)
            print(f"üìã Cabe√ßalho: {header}")
        except StopIteration:
            print("‚ùå Arquivo sem cabe√ßalho")
            return {"error": "Arquivo CSV inv√°lido - sem cabe√ßalho"}

        total = 0
        processed = 0
        created = 0
        updated = 0
        errors = 0

        print("üîÑ Processando linhas...")
        row_count = 0
        for row in csv_reader:
            row_count += 1
            print(f"üìÑ Row {row_count}: {len(row)} columns - {row[0][:20] if row and row[0] else 'empty'}")

            # Filtrar apenas linhas que parecem ser cards v√°lidos (ID num√©rico)
            if not row or len(row) < 3:
                print(f"‚ö†Ô∏è Linha ignorada - poucas colunas: {len(row)}")
                errors += 1
                continue

            # Verificar se o primeiro campo parece ser um ID de card v√°lido
            external_id = row[0].strip() if row[0] else ""
            if not external_id or not (external_id.isdigit() or external_id.startswith('IMPORT-')):
                print(f"‚ö†Ô∏è Linha ignorada - ID inv√°lido: '{external_id}'")
                errors += 1
                continue

            total += 1

            try:
                # Mapear dados da linha do CSV para os par√¢metros da SP
                card_data = {
                    "external_card_id": row[0].strip() if row[0] else f"IMPORT-{total}",
                    "title": row[3].strip() if len(row) > 3 and row[3] else f"Card Importado #{total}",
                    "description": row[10].strip() if len(row) > 10 and row[10] else None,
                    "owner_name": row[4].strip() if len(row) > 4 and row[4] else None,
                    "deadline_str": row[5].strip() if len(row) > 5 and row[5] else None,
                    "priority": row[6].strip() if len(row) > 6 and row[6] else "Average",
                    "column_name": row[7].strip() if len(row) > 7 and row[7] else None,
                    "actual_end_date_str": row[12].strip() if len(row) > 12 and row[12] else None,
                    "last_start_date_str": row[14].strip() if len(row) > 14 and row[14] else None,
                    "last_comment": row[17].strip() if len(row) > 17 and row[17] else None,
                    "card_url": row[16].strip() if len(row) > 16 and row[16] else None,
                }

                print(f"üìù [{total}] Processando: {card_data['external_card_id']} - {card_data['title'][:30]}...")

                print(f"üîç Processando card: {card_data['external_card_id']}")

                try:
                    # Parse dates
                    from datetime import datetime
                    due_date = None
                    completed_date = None
                    start_date = None

                    if card_data['deadline_str']:
                        try:
                            due_date = datetime.strptime(card_data['deadline_str'], '%Y-%m-%d')
                        except:
                            pass

                    if card_data['actual_end_date_str']:
                        try:
                            completed_date = datetime.strptime(card_data['actual_end_date_str'], '%Y-%m-%d %H:%M:%S')
                        except:
                            pass

                    if card_data['last_start_date_str']:
                        try:
                            start_date = datetime.strptime(card_data['last_start_date_str'], '%Y-%m-%d %H:%M:%S')
                        except:
                            pass

                    # CREATE: Card novo (simplificado - sem verificar exist√™ncia)
                    column_id = 1  # Default: Backlog

                    card = await service.card_repo.create(
                        company_id=current_user.company_id,
                        user_id=current_user.id,
                        column_id=column_id,
                        title=card_data['title'],
                        description=card_data['description'],
                        priority=card_data['priority'],
                        due_date=due_date
                    )

                    # Atualizar campos adicionais
                    update_extra = {"ExternalCardID": card_data['external_card_id']}
                    if completed_date:
                        update_extra["CompletedDate"] = completed_date
                    if start_date:
                        update_extra["StartDate"] = start_date

                    await service.card_repo.update(
                        card_id=card.CardID,
                        company_id=current_user.company_id,
                        **update_extra
                    )

                    # Criar movimento de cria√ß√£o
                    await service.movement_repo.create(
                        card_id=card.CardID,
                        user_id=current_user.id,
                        subject="Card Criado (Importado)",
                        old_column_id=None,
                        new_column_id=column_id
                    )

                    # Adicionar coment√°rio se houver
                    if card_data['last_comment']:
                        await service.movement_repo.create(
                            card_id=card.CardID,
                            user_id=current_user.id,
                            subject="Coment√°rio da Importa√ß√£o",
                            description=card_data['last_comment'],
                            movement_type="Comment"
                        )

                    created += 1
                    processed += 1
                    print(f"‚úÖ Card created: {card_data['external_card_id']} (ID: {card.CardID})")

                except Exception as e:
                    print(f"‚ùå Erro ao processar card {card_data['external_card_id']}: {str(e)}")
                    # Don't print full traceback to avoid spam
                    errors += 1

            except Exception as e:
                print(f"‚ùå Erro na linha {total}: {str(e)}")
                print(f"   Row data: {row[:5]}...")  # Show first 5 columns
                import traceback
                traceback.print_exc()
                errors += 1

            except Exception as e:
                print(f"‚ùå Erro na linha {total}: {str(e)}")
                print(f"   Row data: {row[:5]}...")  # Show first 5 columns
                import traceback
                traceback.print_exc()
                errors += 1

        result = {
            "total": total,
            "processed": processed,
            "created": created,
            "updated": updated,
            "errors": errors
        }

        print(f"‚úÖ FINAL: {result}")

        return result

    except Exception as e:
        print(f"üí• ERRO GERAL: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"error": f"Erro interno: {str(e)}"}

def preprocess_multiline_csv(content: str, expected_columns: int = 18) -> str:
    """
    Processa CSV multilinha usando o parser nativo do Python.
    O CSV do BusinessMap usa aspas para campos multilinha.
    """
    import io

    # Usar StringIO para processar como arquivo
    input_io = io.StringIO(content)

    # Ler com csv reader que entende aspas
    reader = csv.reader(input_io, delimiter=';', quoting=csv.QUOTE_MINIMAL)

    processed_lines = []
    for row in reader:
        # Reconstruir linha com delimitadores
        processed_lines.append(';'.join(row))

    return '\n'.join(processed_lines)


@router.post("/import-bm")
async def import_businessmap_csv(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Importa cards do BusinessMap via arquivo CSV.

    Formato esperado (separador ;):
    Card ID;Custom ID;Color;Title;Owner;Deadline;Priority;Column Name;Board Name;
    Owners;Description;Lane Name;Actual End Date;Last End Date;Last Start Date;
    Planned Start;Card URL;Last Comment
    """
    from sqlalchemy import text

    print("=" * 80)
    print("üéØ IMPORTA√á√ÉO BUSINESSMAP INICIADA!")
    print("=" * 80)
    print(f"üë§ Usu√°rio: {current_user.email_address} (ID: {current_user.id})")
    print(f"üè¢ Empresa: {current_user.company_id}")
    print(f"üìÅ Arquivo: {file.filename}")
    print(f"üìÑ Tipo: {file.content_type}")
    print(f"üìè Tamanho: {file.size}")
    print("=" * 80)

    # Validar arquivo
    if not file.filename or not file.filename.lower().endswith('.csv'):
        print("‚ùå Arquivo inv√°lido")
        raise HTTPException(status_code=400, detail="Arquivo deve ser CSV")

    try:
        print("üìñ Lendo arquivo...")
        contents = await file.read()
        print(f"üìÑ Tamanho: {len(contents)} bytes")

        if len(contents) == 0:
            print("‚ùå Arquivo vazio")
            raise HTTPException(status_code=400, detail="Arquivo vazio")

        print("üîÑ Decodificando (UTF-8-SIG)...")
        decoded_content = contents.decode('utf-8-sig')
        print(f"üìÑ Texto original: {len(decoded_content)} caracteres")
        
        # ETAPA DE CORRE√á√ÉO: Pr√©-processar o conte√∫do para juntar linhas multilinha
        print("üîÑ Pr√©-processando CSV para juntar linhas...")
        processed_content = preprocess_multiline_csv(decoded_content)
        print(f"üìÑ Texto processado: {len(processed_content)} caracteres")
        print(f"üìÑ Preview: {processed_content[:200]}...")

        print("üìä Processando CSV...")
        csv_reader = csv.reader(io.StringIO(processed_content), delimiter=';')

        try:
            header = next(csv_reader)
            print(f"üìã Cabe√ßalho: {header}")
        except StopIteration:
            print("‚ùå Arquivo sem cabe√ßalho")
            raise HTTPException(status_code=400, detail="Arquivo CSV inv√°lido - sem cabe√ßalho")

        # Carregar todas as linhas para contagem correta
        rows = list(csv_reader)
        total = len(rows)
        processed = 0
        created = 0
        updated = 0
        errors = 0

        print(f"üîÑ Processando {total} linhas v√°lidas...")
        for i, row in enumerate(rows, 1):
            if len(row) < 18: # Checar se a linha tem o n√∫mero esperado de colunas
                print(f"‚ö†Ô∏è Linha {i} ignorada - colunas insuficientes: {len(row)}")
                errors += 1
                continue

            try:
                # Mapear dados da linha do CSV para os par√¢metros da SP
                card_data = {
                    "external_card_id": row[0].strip() if row[0] else f"IMPORT-{i}",
                    "title": row[3].strip() if len(row) > 3 and row[3] else f"Card Importado #{i}",
                    "description": row[10].strip() if len(row) > 10 and row[10] else None,
                    "owner_name": row[4].strip() if len(row) > 4 and row[4] else None,
                    "deadline_str": row[5].strip() if len(row) > 5 and row[5] else None,
                    "priority": row[6].strip() if len(row) > 6 and row[6] else "Average",
                    "column_name": row[7].strip() if len(row) > 7 and row[7] else None,
                    "actual_end_date_str": row[12].strip() if len(row) > 12 and row[12] else None,
                    "last_start_date_str": row[14].strip() if len(row) > 14 and row[14] else None,
                    "last_comment": row[17].strip() if len(row) > 17 and row[17] else None,
                    "card_url": row[16].strip() if len(row) > 16 and row[16] else None,
                }

                print(f"üìù [{i}/{total}] Processando: {card_data['external_card_id']} - {card_data['title'][:30]}...")

                # Query que executa a SP e retorna os valores de OUTPUT como um SELECT
                sp_query = text("""
                    DECLARE @NewCardIDOut INT;
                    DECLARE @ActionTakenOut NVARCHAR(10);
                    EXEC [core].[sp_UpsertCardFromImport]
                        @ExternalCardID = :external_card_id,
                        @Title = :title,
                        @Description = :description,
                        @OwnerName = :owner_name,
                        @DeadlineStr = :deadline_str,
                        @Priority = :priority,
                        @ColumnName = :column_name,
                        @ActualEndDateStr = :actual_end_date_str,
                        @LastStartDateStr = :last_start_date_str,
                        @LastComment = :last_comment,
                        @CardURL = :card_url,
                        @CompanyID = :company_id,
                        @DefaultUserID = :user_id,
                        @NewCardID = @NewCardIDOut OUTPUT,
                        @ActionTaken = @ActionTakenOut OUTPUT;
                    SELECT @NewCardIDOut AS NewCardID, @ActionTakenOut AS ActionTaken;
                """)

                result = await db.execute(sp_query, {
                    **card_data,
                    "company_id": current_user.company_id,
                    "user_id": current_user.id
                })

                sp_result = result.fetchone()
                result.close()  # Libera a conex√£o para o pr√≥ximo comando

                if sp_result and sp_result.ActionTaken:
                    action = sp_result.ActionTaken
                    if action == 'CREATED':
                        created += 1
                    elif action == 'UPDATED':
                        updated += 1
                    processed += 1
                    print(f"‚úÖ Card {action.lower()}: {card_data['external_card_id']}")
                else:
                    print("‚ö†Ô∏è SP n√£o retornou resultado esperado")
                    errors += 1

            except Exception as e:
                print(f"‚ùå Erro na linha {i}: {str(e)}")
                # N√£o fazer rollback aqui para evitar o erro greenlet_spawn
                errors += 1
        
        # Commit ou Rollback final, tratando a importa√ß√£o como uma √∫nica transa√ß√£o
        if errors > 0:
            await db.rollback()
            print(f"‚ö†Ô∏è {errors} erros encontrados. A transa√ß√£o foi revertida.")
        else:
            await db.commit()
            print("‚úÖ Transa√ß√£o comitada com sucesso.")

        result = {
            "total": total,
            "processed": processed,
            "created": created,
            "updated": updated,
            "errors": errors
        }

        print(f"‚úÖ FINAL: {result}")
        return result

    except Exception as e:
        print(f"üí• ERRO GERAL: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao processar arquivo CSV: {str(e)}"
        )
    """
    Importa cards do BusinessMap via arquivo CSV.

    Formato esperado (separador ;):
    Card ID;Custom ID;Color;Title;Owner;Deadline;Priority;Column Name;Board Name;
    Owners;Description;Lane Name;Actual End Date;Last End Date;Last Start Date;
    Planned Start;Card URL;Last Comment
    """
    from sqlalchemy import text

    print("=" * 80)
    print("üéØ IMPORTA√á√ÉO BUSINESSMAP INICIADA!")
    print("=" * 80)
    print(f"üë§ Usu√°rio: {current_user.email_address} (ID: {current_user.id})")
    print(f"üè¢ Empresa: {current_user.company_id}")
    print(f"üìÅ Arquivo: {file}")
    if file:
        print(f"üìÅ Filename: {file.filename}")
        print(f"üìÑ Tipo: {file.content_type}")
        print(f"üìè Tamanho: {file.size}")
    else:
        print("‚ùå Arquivo n√£o recebido!")
        raise HTTPException(status_code=400, detail="Arquivo n√£o enviado")
    print("=" * 80)
    print(f"üë§ Usu√°rio: {current_user.email_address} (ID: {current_user.id})")
    print(f"üè¢ Empresa: {current_user.company_id}")
    print(f"üìÅ Arquivo: {file.filename}")
    print(f"üìÑ Tipo: {file.content_type}")
    print(f"üìè Tamanho: {file.size}")
    print("=" * 80)

    # Validar arquivo
    if not file.filename or not file.filename.lower().endswith('.csv'):
        print("‚ùå Arquivo inv√°lido")
        raise HTTPException(status_code=400, detail="Arquivo deve ser CSV")

    try:
        print("üìñ Lendo arquivo...")
        contents = await file.read()
        print(f"üìÑ Tamanho: {len(contents)} bytes")

        if len(contents) == 0:
            print("‚ùå Arquivo vazio")
            raise HTTPException(status_code=400, detail="Arquivo vazio")

        print("üîÑ Decodificando...")
        decoded = contents.decode('utf-8')
        print(f"üìÑ Texto: {len(decoded)} caracteres")
        print(f"üìÑ Preview: {decoded[:100]}...")

        print("üìä Processando CSV...")
        csv_reader = csv.reader(io.StringIO(decoded), delimiter=';')

        # Pular cabe√ßalho
        try:
            header = next(csv_reader)
            print(f"üìã Cabe√ßalho: {header}")
        except StopIteration:
            print("‚ùå Arquivo sem cabe√ßalho")
            raise HTTPException(status_code=400, detail="Arquivo CSV inv√°lido - sem cabe√ßalho")

        total = 0
        processed = 0
        created = 0
        updated = 0
        errors = 0

        print("üîÑ Processando linhas...")
        for row in csv_reader:
            if len(row) < 3:  # Pelo menos ID, t√≠tulo b√°sico
                print(f"‚ö†Ô∏è Linha ignorada - poucas colunas: {len(row)}")
                errors += 1
                continue

            total += 1

            try:
                # Mapear dados b√°sicos
                external_card_id = row[0].strip() if row[0] else f"IMPORT-{total}"
                title = row[3].strip() if len(row) > 3 and row[3] else f"Card Importado #{total}"

                print(f"üìù [{total}] Processando: {external_card_id} - {title[:30]}...")

                # Chamar SP com par√¢metros m√≠nimos
                print("üîç Chamando SP...")
                result = await db.execute(
                    text("""
                        EXEC [core].[sp_UpsertCardFromImport]
                            @ExternalCardID = :id,
                            @Title = :title,
                            @CompanyID = :company,
                            @DefaultUserID = :user
                    """),
                    {
                        "id": external_card_id,
                        "title": title,
                        "company": current_user.company_id,
                        "user": current_user.id
                    }
                )

                sp_result = result.fetchone()
                print(f"üì• SP Resultado: {sp_result}")

                if sp_result:
                    action = sp_result[1] if len(sp_result) > 1 else None
                    print(f"‚úÖ A√ß√£o: {action}")

                    if action == 'CREATED':
                        created += 1
                        processed += 1
                    elif action == 'UPDATED':
                        updated += 1
                        processed += 1
                    else:
                        print(f"‚ö†Ô∏è A√ß√£o desconhecida: {action}")
                else:
                    print("‚ö†Ô∏è SP n√£o retornou resultado")
                    errors += 1

            except Exception as e:
                print(f"‚ùå Erro na linha {total}: {str(e)}")
                import traceback
                traceback.print_exc()
                errors += 1

        print("üíæ Fazendo commit...")
        await db.commit()

        result = {
            "total": total,
            "processed": processed,
            "created": created,
            "updated": updated,
            "errors": errors
        }

        print(f"‚úÖ FINAL: {result}")

        return result

    except Exception as e:
        print(f"üí• ERRO GERAL: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

    print(f"‚úÖ Arquivo v√°lido: {file.filename}")
    print(f"üìÑ Tipo MIME: {file.content_type}")
    print(f"üìÑ Tamanho estimado: {file.size if hasattr(file, 'size') else 'desconhecido'}")
    
    try:
        print("üöÄ Iniciando processamento do CSV...")

        # Ler conte√∫do do arquivo
        contents = await file.read()
        print(f"üìÑ Arquivo lido: {len(contents)} bytes")

        if len(contents) == 0:
            print("‚ùå Arquivo vazio!")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Arquivo CSV est√° vazio"
            )

        decoded = contents.decode('utf-8')
        print(f"üìÑ Conte√∫do decodificado: {len(decoded)} caracteres")
        print(f"üìÑ Primeiras 200 chars: {decoded[:200]}")

        # PR√â-PROCESSAR: Juntar linhas multilinha
        print("üîÑ Pr√©-processando CSV para juntar linhas multilinha...")
        decoded = preprocess_multiline_csv(decoded, expected_columns=18)
        print(f"‚úÖ Pr√©-processamento conclu√≠do")

        # IMPORTANTE: Usar quoting para suportar campos multilinha
        csv_reader = csv.reader(
            io.StringIO(decoded), 
            delimiter=';',
            quotechar='"',
            quoting=csv.QUOTE_MINIMAL,
            skipinitialspace=True
        )
        print("üìÑ CSV reader criado")
        
        # Pular cabe√ßalho
        header = next(csv_reader)
        print(f"üìã Cabe√ßalho: {len(header)} colunas")
        
        # Estat√≠sticas
        total = 0
        processed = 0
        created = 0
        updated = 0
        errors = 0
        
        # Processar cada linha
        for row in csv_reader:
            # Validar ANTES de contar como total
            if len(row) < 17:  # Validar n√∫mero m√≠nimo de colunas
                print(f"‚ö†Ô∏è  Linha ignorada - poucas colunas: {len(row)}")
                errors += 1
                continue

            # Agora sim, √© uma linha v√°lida
            total += 1
            print(f"üìù [{total}] Processando: {row[0]} - {row[3][:50] if len(row) > 3 else 'Sem t√≠tulo'}")
            
            try:
                # Mapear colunas do CSV
                external_card_id = row[0].strip() if row[0] else None
                title = row[3].strip() if len(row) > 3 and row[3] else "Card Importado"
                owner_name = row[4].strip() if len(row) > 4 and row[4] else None
                deadline = row[5].strip() if len(row) > 5 and row[5] else None
                priority = row[6].strip() if len(row) > 6 and row[6] else "Average"
                column_name = row[7].strip() if len(row) > 7 and row[7] else None
                description = row[10].strip() if len(row) > 10 and row[10] else None
                actual_end_date = row[12].strip() if len(row) > 12 and row[12] else None
                last_end_date = row[13].strip() if len(row) > 13 and row[13] else None
                last_start_date = row[14].strip() if len(row) > 14 and row[14] else None
                planned_start = row[15].strip() if len(row) > 15 and row[15] else None
                card_url = row[16].strip() if len(row) > 16 and row[16] else None
                last_comment = row[17].strip() if len(row) > 17 and row[17] else None
                
                # Debug: mostrar dados que ser√£o enviados
                print(f"Enviando para SP: CardID={external_card_id}, Title={title[:30]}..., Column={column_name}")

                # Chamar stored procedure com par√¢metros corretos
                result = await db.execute(
                    text("""
                        EXEC [core].[UpsertCardFromImport]
                            @CompanyID = :company_id,
                            @UserID = :user_id,
                            @ExternalCardID = :external_card_id,
                            @Title = :title,
                            @Description = :description,
                            @ColumnName = :column_name,
                            @Priority = :priority,
                            @Deadline = :deadline,
                            @StartDate = :start_date,
                            @CompletedDate = :completed_date,
                            @LastComment = :last_comment,
                            @Size = :size
                    """),
                    {
                        "company_id": current_user.company_id,
                        "user_id": current_user.id,
                        "external_card_id": external_card_id,
                        "title": title,
                        "description": description,
                        "column_name": column_name,
                        "priority": priority,
                        "deadline": deadline if deadline else None,
                        "start_date": last_start_date if last_start_date else planned_start,
                        "completed_date": actual_end_date if actual_end_date else last_end_date,
                        "last_comment": last_comment,
                        "size": None  # Pode ser extra√≠do depois se necess√°rio
                    }
                )
                
                # Obter resultado da SP (retorna CardID)
                sp_result = result.fetchone()
                if sp_result and sp_result[0]:
                    card_id = sp_result[0]
                    print(f"‚úÖ Card processado: ID={card_id}")
                    processed += 1
                    # Considerar como criado/atualizado baseado na exist√™ncia pr√©via
                    # (simplificado - a SP faz upsert automaticamente)
                    created += 1
                else:
                    print("‚ö†Ô∏è SP n√£o retornou CardID")
                    errors += 1
                
            except Exception as e:
                print(f"‚ùå Erro na linha {total}: {str(e)}")
                import traceback
                traceback.print_exc()
                errors += 1
                # Don't continue processing if there's an error in the first few rows
                if total <= 3:
                    raise e
                continue

        # Commit das transa√ß√µes
        await db.commit()

        print(f"‚úÖ Importa√ß√£o finalizada: Total={total}, Processados={processed}, Criados={created}, Atualizados={updated}, Erros={errors}")

        return {
            "total": total,
            "processed": processed,
            "created": created,
            "updated": updated,
            "errors": errors
        }

    except Exception as e:
        print(f"üí• ERRO GERAL na importa√ß√£o: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao processar arquivo CSV: {str(e)}"
        )
    
    return None


# ============================================================================
# Relat√≥rios ITIL
# ============================================================================

@router.get("/analytics/itil-summary")
async def get_itil_summary(
    start_date: str = Query(..., description="Data inicial (YYYY-MM-DD)"),
    end_date: str = Query(..., description="Data final (YYYY-MM-DD)"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Resumo executivo ITIL com m√©tricas por categoria.
    
    Retorna estat√≠sticas agregadas por categoria ITIL:
    - Total de cards
    - Tempo m√©dio de ciclo
    - SLA Compliance
    - Contadores de risco e metadados
    """
    company_id = current_user.company_id
    if not company_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Usu√°rio deve pertencer a uma empresa"
        )
    
    query = text("""
        SELECT 
            ITILCategory,
            COUNT(*) AS TotalCards,
            AVG(CycleTimeSeconds) AS AvgCycleTime,
            SUM(MetSLA) * 100.0 / NULLIF(COUNT(*), 0) AS SLACompliance,
            SUM(CASE WHEN RiskLevel = 'High' THEN 1 ELSE 0 END) AS HighRiskCount,
            SUM(CASE WHEN HasWindow = 1 THEN 1 ELSE 0 END) AS WithWindow,
            SUM(CASE WHEN HasCAB = 1 THEN 1 ELSE 0 END) AS WithCAB,
            SUM(CASE WHEN HasBackout = 1 THEN 1 ELSE 0 END) AS WithBackout
        FROM analytics.vw_ITILReport
        WHERE CompletedDate BETWEEN :start_date AND :end_date
        AND CompanyID = :company_id
        GROUP BY ITILCategory
        ORDER BY TotalCards DESC
    """)
    
    try:
        result = await db.execute(query, {
            "start_date": start_date,
            "end_date": end_date,
            "company_id": company_id
        })
        
        rows = result.fetchall()
        
        return [
            {
                "itilCategory": row[0],
                "totalCards": row[1],
                "avgCycleTime": row[2],
                "slaCompliance": float(row[3]) if row[3] else 0.0,
                "highRiskCount": row[4],
                "withWindow": row[5],
                "withCAB": row[6],
                "withBackout": row[7]
            }
            for row in rows
        ]
    except Exception as e:
        logger.error(f"Error fetching ITIL summary: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao buscar resumo ITIL: {str(e)}"
        )


@router.get("/analytics/itil-cards")
async def get_itil_cards(
    start_date: str = Query(..., description="Data inicial (YYYY-MM-DD)"),
    end_date: str = Query(..., description="Data final (YYYY-MM-DD)"),
    itil_category: Optional[str] = Query(None, description="Filtrar por categoria ITIL"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Lista detalhada de cards com classifica√ß√£o ITIL.
    """
    company_id = current_user.company_id
    if not company_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Usu√°rio deve pertencer a uma empresa"
        )
    
    # Query base
    sql = """
        SELECT 
            CardID, ExternalCardID, Title, Description, ColumnName,
            ITILCategory, Priority, RiskLevel, HasWindow, HasCAB, HasBackout,
            StartDate, CompletedDate, DueDate, MetSLA, DaysLate
        FROM analytics.vw_ITILReport
        WHERE CompletedDate BETWEEN :start_date AND :end_date
        AND CompanyID = :company_id
    """
    
    # Adicionar filtro de categoria se fornecido
    if itil_category:
        sql += " AND ITILCategory = :itil_category"
    
    sql += " ORDER BY CompletedDate DESC"
    
    query = text(sql)
    
    try:
        params = {
            "start_date": start_date,
            "end_date": end_date,
            "company_id": company_id
        }
        
        if itil_category:
            params["itil_category"] = itil_category
        
        result = await db.execute(query, params)
        rows = result.fetchall()
        
        return [
            {
                "cardId": row[0],
                "externalCardId": row[1],
                "title": row[2],
                "description": row[3],
                "columnName": row[4],
                "itilCategory": row[5],
                "priority": row[6],
                "riskLevel": row[7],
                "hasWindow": bool(row[8]),
                "hasCAB": bool(row[9]),
                "hasBackout": bool(row[10]),
                "startDate": row[11].isoformat() if row[11] else None,
                "completedDate": row[12].isoformat() if row[12] else None,
                "dueDate": row[13].isoformat() if row[13] else None,
                "metSLA": bool(row[14]) if row[14] is not None else None,
                "daysLate": row[15]
            }
            for row in rows
        ]
    except Exception as e:
        logger.error(f"Error fetching ITIL cards: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao buscar cards ITIL: {str(e)}"
        )
